{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/522'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nilearn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nilearn) (0.0)\n",
      "Requirement already satisfied: scipy>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nilearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nilearn) (1.14.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nilearn) (0.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nilearn) (0.14.1)\n",
      "Requirement already satisfied: nibabel>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nilearn) (3.1.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nibabel>=2.0.2->nilearn) (20.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=14.3->nibabel>=2.0.2->nilearn) (2.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=14.3->nibabel>=2.0.2->nilearn) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.5.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch) (1.14.3)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.6.0)\n",
      "Requirement already satisfied: torch==1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchvision) (1.5.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchvision) (5.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchvision) (1.14.3)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch==1.5.0->torchvision) (0.18.2)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.46.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nilearn\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip native_2.zip\n",
    "# !unzip native_1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib_images = []\n",
    "nib_lesions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir in os.listdir('native_1'):\n",
    "    if subdir != '.DS_Store':\n",
    "        look = 'native_1' + '/' + subdir\n",
    "        for subsubdir in os.listdir(look):\n",
    "            if subsubdir != '.DS_Store':\n",
    "                sublook = look + '/' + subsubdir\n",
    "                nib_images.append(nib.load(sublook + '/' + subsubdir +'.nii.gz'))\n",
    "                nib_lesions.append(nib.load(sublook + '/' + subsubdir + '_LesionSmooth.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir in os.listdir('native_2'):\n",
    "    if subdir != '.DS_Store':\n",
    "        look = 'native_2' + '/' + subdir\n",
    "        for subsubdir in os.listdir(look):\n",
    "            if subsubdir != '.DS_Store':\n",
    "                sublook = look + '/' + subsubdir\n",
    "                nib_images.append(nib.load(sublook + '/' + subsubdir +'.nii.gz'))\n",
    "                nib_lesions.append(nib.load(sublook + '/' + subsubdir + '_LesionSmooth.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [48, 56, 62, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_train(brain, lesion,num):\n",
    "    s0, s1, s2 = brain.shape\n",
    "    ran = 0.009\n",
    "    features = []\n",
    "    flat_feat = []\n",
    "    labels = []\n",
    "    flat_lab = []\n",
    "    for k in range(s2-50):\n",
    "        for i in range(s0 - 100):\n",
    "            for j in range(s1 - 100):\n",
    "                if lesion[i+50, j+50, k+25] != 0 or random.random() < ran:\n",
    "                    selection = brain[i+38:i+63, j+38:j+63, k+25]\n",
    "                    l_selection = lesion[i+50, j+50, k+25]\n",
    "                    features.append(selection)\n",
    "                    labels.append(l_selection)\n",
    "                    if num < 5:\n",
    "                        flat_feat.append(selection.reshape(selection.shape[0]**2))\n",
    "                        flat_lab.append(l_selection)\n",
    "    return features, labels, flat_feat, flat_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_rf(brain, lesion):\n",
    "    s0, s1, s2 = brain.shape\n",
    "    ran = 0.04\n",
    "    ran2 = 0.005\n",
    "    # num = (s0 - 50) * (s1 - 50) * s2\n",
    "    flat_feat = []\n",
    "    flat_lab = []\n",
    "    for k in range(s2-50):\n",
    "        for i in range(s0 - 100):\n",
    "            for j in range(s1 - 100):\n",
    "                l = lesion[i+50, j+50, k+25]\n",
    "                if (l==1 and random.random()<ran2) or (l==0 and random.random() < ran):\n",
    "                    selection = brain[i+38:i+63, j+38:j+63, k+25]\n",
    "                    l_selection = lesion[i+50, j+50, k+25]\n",
    "                    flat_feat.append(selection.reshape(selection.shape[0]**2))\n",
    "                    flat_lab.append(l_selection)\n",
    "    return flat_feat, flat_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_test(brain, lesion):\n",
    "    s0, s1, s2 = brain.shape\n",
    "    ran = 0.03\n",
    "    ran2 = 0.2\n",
    "    # num = (s0 - 50) * (s1 - 50) * s2\n",
    "    features = []\n",
    "    labels = []\n",
    "    for k in range(s2-50):\n",
    "        for i in range(s0 - 100):\n",
    "            for j in range(s1 - 100):\n",
    "                l = lesion[i+50, j+50, k+25]\n",
    "                if (l==1 and random.random()<ran2) or (l==0 and random.random() < ran):\n",
    "                    selection = brain[i+38:i+63, j+38:j+63, k+25]\n",
    "                    l_selection = lesion[i+50, j+50, k+25]\n",
    "                    features.append(selection)\n",
    "                    labels.append(l_selection)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = (256, 256, 185)\n",
    "def padding(brain, lesion):\n",
    "    padded_brain = np.zeros(max_size)\n",
    "    padded_lesion = np.zeros(max_size)\n",
    "    s0, s1, s2 = brain.shape\n",
    "\n",
    "    h = int(np.floor((max_size[0] - s0)/2))\n",
    "    w = int(np.floor((max_size[1] - s1)/2))\n",
    "    f = int(np.floor((max_size[2] - s2)/2))\n",
    "\n",
    "    padded_brain[h:h+s0, w:w+s1, f:f+s2] = brain\n",
    "    padded_lesion[h:h+s0, w:w+s1, f:f+s2] = lesion\n",
    "\n",
    "    return padded_brain, padded_lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:38<00:00,  6.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Store Slices Here\n",
    "brain_data = []\n",
    "X_train = []\n",
    "lesion_data = []\n",
    "y_train = []\n",
    "for i in tqdm.tqdm(range(25)):\n",
    "    if i not in d: # where brain sizes and lesion sizes are different\n",
    "        img, lesion = nib_images[i], nib_lesions[i]\n",
    "        # normalize\n",
    "        brain = img.get_fdata()/255\n",
    "        lesion = lesion.get_fdata()/255\n",
    "        #reshape for consistency\n",
    "        if i < 31:\n",
    "          brain = np.rot90(brain,1,axes=(0,2)).copy()\n",
    "          lesion = np.rot90(lesion,1,axes=(0,2)).copy()\n",
    "        elif i > 85:\n",
    "          brain = np.swapaxes(brain,1,2).copy()\n",
    "          brain = np.rot90(brain,1,axes=(0,2)).copy()\n",
    "          lesion = np.swapaxes(lesion,1,2).copy()\n",
    "          lesion = np.rot90(lesion,1,axes=(0,2)).copy()\n",
    "        brain = exposure.equalize_hist(brain)\n",
    "        #slice\n",
    "        if brain.shape[0:2] < (50, 50):\n",
    "            continue\n",
    "        features, labels, flattened_X, flattened_y = get_features_train(brain, lesion,i)\n",
    "        \n",
    "#         print(features[0].shape)\n",
    "        brain_data.extend(features)\n",
    "        lesion_data.extend(labels)\n",
    "        X_train.extend(flattened_X)\n",
    "        y_train.extend(flattened_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Store Slices Here\n",
    "brain_data_valid = []\n",
    "lesion_data_valid = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "for i in tqdm.tqdm(range(50,60)):\n",
    "    if i not in d: # where brain sizes and lesion sizes are different\n",
    "#         if i%10 == 0:\n",
    "#           print(i)\n",
    "        img, lesion = nib_images[i], nib_lesions[i]\n",
    "        # normalize\n",
    "        brain = img.get_fdata()/255\n",
    "        lesion = lesion.get_fdata()/255\n",
    "        #reshape for consistency\n",
    "        if i < 31:\n",
    "          brain = np.rot90(brain,1,axes=(0,2)).copy()\n",
    "          lesion = np.rot90(lesion,1,axes=(0,2)).copy()\n",
    "        elif i > 85:\n",
    "          brain = np.swapaxes(brain,1,2).copy()\n",
    "          brain = np.rot90(brain,1,axes=(0,2)).copy()\n",
    "          lesion = np.swapaxes(lesion,1,2).copy()\n",
    "          lesion = np.rot90(lesion,1,axes=(0,2)).copy()\n",
    "        #slice\n",
    "        if brain.shape[0:2] < (50, 50):\n",
    "            continue\n",
    "        features, labels= get_features_test(brain, lesion)\n",
    "        flattened_X, flattened_y = get_features_rf(brain, lesion)\n",
    "        brain_data_valid.extend(features)\n",
    "        lesion_data_valid.extend(labels)\n",
    "        X_valid.extend(flattened_X)\n",
    "        y_valid.extend(flattened_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# Store Slices Here\n",
    "brain_data_test= []\n",
    "lesion_data_test = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in tqdm.tqdm(range(50,60)):\n",
    "    if i not in d: # where brain sizes and lesion sizes are different\n",
    "        img, lesion = nib_images[i], nib_lesions[i]\n",
    "        # normalize\n",
    "        brain = img.get_fdata()/255\n",
    "        lesion = lesion.get_fdata()/255\n",
    "        #reshape for consistency\n",
    "        if i < 31:\n",
    "          brain = np.rot90(brain,1,axes=(0,2)).copy()\n",
    "          lesion = np.rot90(lesion,1,axes=(0,2)).copy()\n",
    "        elif i > 85:\n",
    "          brain = np.swapaxes(brain,1,2).copy()\n",
    "          brain = np.rot90(brain,1,axes=(0,2)).copy()\n",
    "          lesion = np.swapaxes(lesion,1,2).copy()\n",
    "          lesion = np.rot90(lesion,1,axes=(0,2)).copy()\n",
    "        #slice\n",
    "        if brain.shape[0:2] < (50, 50):\n",
    "            continue\n",
    "        features, labels= get_features_test(brain, lesion)\n",
    "        flattened_X, flattened_y = get_features_rf(brain, lesion)\n",
    "        brain_data_test.extend(features)\n",
    "        lesion_data_test.extend(labels)\n",
    "        X_test.extend(flattened_X)\n",
    "        y_test.extend(flattened_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainsDataset(Dataset):\n",
    "    def __init__(self, brains, lesions, transform=None):\n",
    "        self.brains = brains\n",
    "        self.lesions = lesions\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.brains)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'brain': self.brains[idx], 'lesion': self.lesions[idx]}\n",
    "        if self.transform:\n",
    "            sample['brain'] = self.transform(sample['brain'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=0.56,std=0.41)])\n",
    "brains_dataset = BrainsDataset(brain_data, lesion_data, transform=input_transforms)\n",
    "brains_valid = BrainsDataset(brain_data_valid, lesion_data_valid, transform=input_transforms)\n",
    "brains_test = BrainsDataset(brain_data_test, lesion_data_test, transform=input_transforms)\n",
    "dataloader = DataLoader(brains_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(brains_valid, batch_size = 256, shuffle=False)\n",
    "test_dataloader = DataLoader(brains_test, batch_size = 256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1,n_estimators=50, max_depth=6).fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015063334474495036"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "  if feature_extracting:\n",
    "    for name, param in model.named_parameters(): #.children()\n",
    "      if name[:9] == 'layer4.0.' :  param.requires_grad = True\n",
    "      else: param.requires_grad = False\n",
    "\n",
    "set_parameter_requires_grad(resnet18, feature_extracting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 #We are predicting if a cell is either in or out of the lesion, right? \n",
    "\n",
    "last_input = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(last_input, num_classes)\n",
    "#print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(true, pred):\n",
    "  true = np.array(true)\n",
    "  pred = np.array(pred)\n",
    "  intersection = np.sum(true*pred)\n",
    "  union = np.sum(true == 1) + np.sum(pred == 1)\n",
    "  print(intersection)\n",
    "  return 2*intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet requires 3 channels\n",
    "conv = nn.Conv2d(1,3,5,1,2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader, optimizer, loss, net, test_dataloader):\n",
    "  # TODO: Insert your code here\n",
    "  net = net.to(device)\n",
    "  true = np.array([])\n",
    "  preds = np.array([])\n",
    "  interval_losses = []\n",
    "  for epoch in range(1):\n",
    "    interval_loss = 0\n",
    "    print(datetime.datetime.now())\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_iterator = tqdm.tqdm(train_dataloader)\n",
    "    \n",
    "    for num, data in enumerate(epoch_iterator):\n",
    "      inputs, labels = data['brain'], data['lesion']\n",
    "      inputs, labels = inputs.float().to(device), labels.float().to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      inputs = conv(inputs.float())\n",
    "      outputs = net(inputs)\n",
    "      _, pred = torch.max(outputs, 1)\n",
    "      np.append(preds, pred.cpu().numpy())\n",
    "      np.append(true, labels.cpu().numpy())\n",
    "      loss_value = loss(outputs, labels.long())\n",
    "    \n",
    "      if num%200 == 0 and num!=0:\n",
    "        interval_losses.append(interval_loss/200)\n",
    "        interval_loss = 0\n",
    "      loss_value.backward()\n",
    "\n",
    "      interval_loss += loss_value.item()\n",
    "      optimizer.step()\n",
    "        \n",
    "      total_loss += loss_value.item()\n",
    "    \n",
    "      total += len(labels)\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss/total}, Dice: {test_model(test_dataloader, net)}\")\n",
    "    print()\n",
    "    \n",
    "  return interval_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataloader, net):\n",
    "  # TODO: Insert your code here\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  output_list = np.array([])\n",
    "  true = np.array([])\n",
    "  with torch.no_grad():\n",
    "    for data in tqdm.tqdm(test_dataloader):\n",
    "      inputs, labels = data['brain'], data['lesion']\n",
    "      inputs, labels = inputs.float().to(device), labels.float().to(device)\n",
    "    \n",
    "      inputs = conv(inputs.float())\n",
    "      outputs = net(inputs)\n",
    "      pred = torch.max(outputs, 1)[1]\n",
    "      output_list = np.append(output_list, pred.cpu().numpy())\n",
    "      true = np.append(true, labels.cpu().numpy())\n",
    "\n",
    "    print(np.count_nonzero(output_list))\n",
    "    print(np.count_nonzero(true))\n",
    "    return dice(np.array(output_list), np.array(true))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10740 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 05:52:23.770805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10740/10740 [09:11<00:00, 19.49it/s] \n",
      "  0%|          | 0/1874 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545572.0321578257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1874/1874 [01:22<00:00, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17254 \n",
      " 2054 \n",
      " 520.0 \n",
      " Epoch: 0, Loss: 0.12457895423548721, Train Dice: 0.657124568723548695, Valid Dice: 0.1521546621458879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(resnet18.parameters(), lr=1e-5)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "losses = train_model(dataloader, optimizer, loss_function, resnet18, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training Loss')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(200,10800,200), losses)\n",
    "plt.xlabel('Number of Batches')\n",
    "plt.ylabel('Training Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176164 \n",
      "23272 \n",
      "150085.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14596618609999715"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(test_dataloader, resnet18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
